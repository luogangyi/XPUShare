# 自适应流控窗口测试日志分析

根据提供的 4 个测试容器日志，我们对新实现的自适应流控机制进行了验证。结果表明修改**符合预期**，显著改善了显存抖动时的性能表现。

## 1. 关键预期验证

### A. 预热期 (Warm-up Period) 生效
**预期**: 在刚获得锁的初期（前 30-60秒），即使发生严重超时，窗口也不应降级，而是继续增长。
**日志证据**:
- `nvshare-cross-gpu-1`: `Received LOCK_OK` 后，窗口指数级增长：
  ```
  [DEBUG]: Pending Kernel Window is 128 (warmup=1).
  [DEBUG]: Pending Kernel Window is 256 (warmup=1).
  [DEBUG]: Pending Kernel Window is 512 (warmup=1).
  ```
  注意 `warmup=1` 标志一直为真。这期间即使有换页开销，窗口也没有停止增长，允许流水线被迅速填满。
- **对比**: 在旧版本中，一旦出现卡顿，窗口会立即降为 1。现在我们看到了 `512` 的大窗口，这意味着并行度极高。

### B. 吞吐量保持
**预期**: 即使在多租户切换场景下，吞吐量应维持在较高水平，不再出现 35s/it 的崩溃。
**日志证据**:
- 容器 1: `21.96it/s`, `24.94it/s`, `25.87it/s`.
- 容器 3: `15.80it/s`, `24.10it/s`, `25.69it/s`.
- **关键现象**: 在 `warmup=0`（预热结束）且发生 `DROP_LOCK` 前，速度稳定在 **25 it/s** 左右。
- **异常点**: 容器 1 在 `Received LOCK_OK` 后曾短暂出现 `1.54it/s` -> `5.04it/s` 的爬坡过程，但这正是预热期发挥作用的时候——窗口正在从小变大，速度随之提升。如果没有预热保护，这个爬坡过程会被打断并锁定在低速。

### C. AIMD 降级机制
**预期**: 当预热结束后，如果发生拥塞，窗口应平滑收缩而非重置。
**日志证据**:
- 容器 1 (`02:39`): `Pending Kernel Window is 256 (warmup=1)` -> `warmup` 结束 -> `Pending Kernel Window is 204 (warmup=0)`.
- 随后: `163` -> `130` -> `104` -> `83`...
- **分析**: 这是 AIMD 的 **乘性减** (Multiplicative Decrease) 生效了。它检测到了轻微拥堵（可能 sync 时间 > 1s），于是将窗口 `* 0.8` 平滑下调，寻找网络/PCIe 带宽的平衡点，而不是直接置 1。
- 只有在极少数时刻（如 `DROP_LOCK` 发生瞬间），窗口被重置为 4，这是为了快速释放锁。

### D. 显存超卖行为
**日志**: `[WARN]: Enabling GPU memory oversubscription`
**状态**: 各容器都分配了 12GB (`cuMemAllocManaged` allocated ~3GB * 4), 总计 48GB 需求运行在 16GB 显存上。
**结果**: 任务在不断切换锁，但每次获得锁后都能恢复到 ~25 it/s 的满速运行。说明数据换入换出虽然有开销（爬坡期），但一旦 Working Set 就绪，自适应窗口确实防止了流控误判，维持了高吞吐。

## 2. 只有一点小波动
在容器 1 和 3 的日志中，我们看到：
`[04:02<10:20, 1.84it/s]`
这是在重新获得锁（`LOCK_OK`）后的第一秒。由于显存已完全被置换出去，重新换入需要时间。
但随后几行日志显示：
`[04:06] ... 25.81it/s`
速度迅速恢复。证明系统从冷启动恢复的能力极强。

## 结论
测试日志**完全符合预期**。新机制成功地：
1. **避免了死锁/活锁**: 窗口没有卡在 1。
2. **掩盖了换页延迟**: 通过预热期让窗口大胆增长。
3. **稳定了带宽**: AIMD 算法自动找到了各容器在当前拥塞下的最佳并发度 (~200 到 ~40 之间波动，而不是 1)。

建议该版本可以发布。
