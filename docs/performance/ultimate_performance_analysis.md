# nvshare 多任务性能问题终极分析与解决方案

## 1. 问题背景回顾

### 1.1 核心现象

| 场景 | 运行时间 | 相对性能 |
|------|----------|----------|
| Native (nvidia device plugin) | 155 秒 | 100% |
| nvshare 单任务 | 159 秒 | 97.5% |
| nvshare 多任务并发 | > 5000 秒 | **< 3%** |

### 1.2 之前尝试过的优化（均无效）

| 尝试 | 目标 | 结果 | 原因 |
|------|------|------|------|
| 增大 Kernel Window | 提高并行度 | 无效 | 数据不在 GPU，窗口再大也无法执行 |
| 延长时间片 | 延长有效计算时间 | 效果有限 | 47秒恢复开销仍存在 |
| 显存配额管理 | 控制分配 | 无效 | 解决"分配给谁"，不解决"如何快速恢复" |
| **cuMemAdvise** | 设置首选位置 | **无效** | 只是提示，驱动可忽略 |
| **cuMemPrefetchAsync** | 批量预取 | **无效** | 显存满时被驱动忽略 |

---

## 2. 预取失败的根本原因

### 2.1 为什么 cuMemAdvise 无效？

```
cuMemAdvise(ptr, size, CU_MEM_ADVISE_SET_PREFERRED_LOCATION, device)
```

这只是告诉驱动：**"当这个页面将来被访问时，请尽量放在 GPU 上"**。

**关键问题**：
- 它不会立即触发数据迁移
- 驱动可以忽略这个建议（尤其是显存紧张时）
- 对"未分配物理页"（First Touch 前）的内存完全无效

### 2.2 为什么 cuMemPrefetchAsync 也无效？

实测结果：
```
[NVSHARE][INFO]: Prefetch: Done. DMA migration took 0.000 seconds
[NVSHARE][WARN]: Warmup: Ignored critical timeout (28 s)
```

**预取耗时 0.000 秒** = 驱动直接忽略了请求

**失败原因一：First Touch 问题**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        First Touch 问题示意图                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Step 1: cuMemAllocManaged(12GB)                                            │
│          → 只分配了虚拟地址 (VA)，物理页 = 0                                 │
│                                                                             │
│  Step 2: cuMemPrefetchAsync(ptr, 12GB, device)                              │
│          → 驱动检查："这些 VA 没有对应的物理页，没有数据需要迁移"            │
│          → 直接返回成功，耗时 0.000 秒                                       │
│                                                                             │
│  Step 3: PyTorch Kernel 开始访问内存                                         │
│          → 触发真正的缺页中断 (Page Fault)                                   │
│          → 驱动逐页分配物理内存                                              │
│          → 耗时 ~28-50 秒                                                    │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**失败原因二：显存已满**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        显存压力下的驱动行为                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  GPU 显存: 16 GB                                                             │
│  正在运行：4 个 Pod × 12GB = 48GB 逻辑需求                                   │
│                                                                             │
│  nvidia-smi 显示: 14911 MiB Used (几乎全满)                                  │
│                                                                             │
│  当 Pod B 调用 cuMemPrefetchAsync 时:                                        │
│    → 驱动检查："GPU 没有空闲页，无法执行预取"                                 │
│    → 选项 1: 主动驱逐其他进程的页面（昂贵，驱动不愿意做）                     │
│    → 选项 2: 忽略预取请求（驱动实际选择）                                     │
│                                                                             │
│  结果: cuMemPrefetchAsync 变成 No-Op                                         │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.3 核心结论

> **在显存超卖场景下，UVM 的"自动管理"和"预取提示"都是不可靠的。**
> **驱动会根据自己的策略决定是否执行，用户态无法强制控制。**

---

## 3. 真正可行的解决方案

### 方案对比

| 方案 | 核心思路 | 可行性 | 性能预期 | 代价 |
|------|----------|--------|----------|------|
| **A. 串行独占** | 一次只运行一个任务 | ✅ 高 | 恢复原速 | 并发度=1 |
| **B. Manual Swap** | 用户态强制显存交换 | ⚠️ 中 | 切换~1秒 | 内存翻倍 |
| **C. 限制并发数** | 只调度能放下的任务 | ✅ 高 | 多任务加速 | 需显存感知 |
| **D. 放弃 UVM** | 使用原生 cudaMalloc | ❌ 低 | 无超卖 | 架构重构 |

---

### 方案 A: 串行独占执行（推荐首选）

**核心思路**：在显存严重超卖时，完全避免并发，一次只允许一个任务使用 GPU。

**为什么这是最简单有效的方案？**

回顾您的观察：
- **单任务 nvshare 耗时 159 秒** ≈ 原生性能
- **问题根源**：多任务切换时的内存迁移开销

如果任务 A 完全运行完毕再运行任务 B，则：
- 任务 A：159 秒 (单独运行，无切换)
- 任务 B：159 秒 (单独运行，无切换)
- 总计：318 秒

**对比当前多任务并发**：> 5000 秒

```
改进比: 5000 / 318 ≈ 15x 性能提升
```

**实现方式**：

```c
// scheduler.c: 在 try_schedule 中添加串行模式

static int serial_mode = 0;  // 环境变量控制

static void try_schedule(struct gpu_context* ctx) {
    // 如果启用串行模式，且当前有任务在运行，则等待
    if (serial_mode && ctx->lock_held) {
        log_info("Serial mode: waiting for current task to complete");
        return;  // 不调度新任务
    }
    
    // 原有调度逻辑...
}
```

**配置**：
```bash
export NVSHARE_SERIAL_MODE=1  # 启用串行执行
```

---

### 方案 B: Manual Host Swap (Shadow Buffer)

**核心思路**：不依赖 UVM 的自动管理，由 libnvshare 维护 Host 端的"影子内存"，强制控制数据位置。

**工作流程**：

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        Manual Swap 工作流程                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  任务 A 运行中:                                                              │
│    GPU: [████████ A 的数据 (12GB) ████████]                                 │
│    Host: [░░░░░░ 空的影子缓冲区 ░░░░░░░░░]                                   │
│                                                                             │
│  时间片到期，切换到任务 B:                                                   │
│                                                                             │
│  Step 1: 备份 A 的数据到 Host (cudaMemcpy D2H)                              │
│          耗时: 12GB / 12GB/s ≈ 1 秒                                          │
│    GPU: [████████ A 的数据 ████████]                                         │
│    Host: [████████ A 的备份 ████████]                                        │
│                                                                             │
│  Step 2: 释放 A 在 GPU 的空间 (cuMemFree)                                    │
│    GPU: [░░░░░░░░ 空 ░░░░░░░░░░░░░]                                          │
│                                                                             │
│  Step 3: 恢复 B 的数据到 GPU (cudaMemcpy H2D)                               │
│          耗时: 12GB / 12GB/s ≈ 1 秒                                          │
│    GPU: [████████ B 的数据 ████████]                                         │
│                                                                             │
│  总切换时间: ~2-3 秒 (vs 当前 ~50 秒)                                        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**代价**：
- Host 内存消耗翻倍（每个任务需要等量的 Host Pinned Memory）
- 代码复杂度增加（需跟踪脏页、管理影子缓冲区）

**实现难度**：高

---

### 方案 C: 显存感知 + 限制并发（推荐配合使用）

**核心思路**：根据实际显存容量，只同时调度能够容纳的任务。

**示例**：

| GPU 显存 | 任务显存需求 | 最大并发数 | 策略 |
|----------|--------------|------------|------|
| 16 GB | 4 GB × N | 4 | 4 个任务可并行 |
| 16 GB | 12 GB × N | 1 | 串行执行 |
| 24 GB | 12 GB × N | 2 | 2 个任务可并行 |

**实现**：当前的 `memory_aware_scheduling` 已经实现了基础框架，但需要更严格的准入控制。

```c
// 更严格的并发控制
static int can_run_with_memory(struct gpu_context* ctx,
                               struct nvshare_client* client) {
    // 当前已运行任务的显存总量
    size_t running = ctx->running_memory_usage;
    // 新任务需要的显存
    size_t needed = client->memory_allocated;
    // 物理显存限制（减去系统开销）
    size_t limit = ctx->total_memory * 85 / 100;  // 保留 15%
    
    // 严格检查：只有当显存确实足够时才允许并发
    if (running + needed <= limit) {
        return 1;  // 可以并发
    }
    
    // 如果当前没有任务运行，允许这个任务运行（避免死锁）
    if (running == 0) {
        return 1;
    }
    
    return 0;  // 需要等待
}
```

---

## 4. 推荐实施路径

### 阶段 1: 快速验证 - 串行模式（1 天）

**目标**：验证串行执行能否恢复单任务性能

**实施**：
1. 添加 `NVSHARE_SERIAL_MODE` 环境变量
2. 修改 `try_schedule` 启用串行逻辑

**验证**：
```bash
# 多个任务依次执行，不并发
export NVSHARE_SERIAL_MODE=1
# 启动多个任务
python tests/pytorch-add.py &
python tests/pytorch-add.py &
# 观察：任务应依次完成，每个约 160 秒
```

### 阶段 2: 优化 - 显存感知限制（3 天）

**目标**：智能决定并发数量

**实施**：
1. 当显存能容纳多个任务时，允许并发
2. 当显存超卖时，自动降级为串行

### 阶段 3: 高级优化 - Manual Swap（可选，2 周）

**目标**：在必须并发的场景下，将切换时间从 50 秒降至 2-3 秒

**适用场景**：
- 交互式多用户场景
- 必须保证响应延迟的场景

---

## 5. 技术深度分析：为什么 UVM 在超卖场景下表现糟糕

### 5.1 UVM 的设计假设

CUDA Unified Memory 的设计目标是：
1. 简化编程模型（程序员不用手动管理数据位置）
2. 自动优化数据放置（驱动根据访问模式迁移）

**隐含假设**：物理显存足以容纳热数据 (Working Set)

### 5.2 超卖场景为何打破假设

当显存需求 > 物理显存时：
1. 驱动被迫频繁驱逐页面
2. 每次驱逐/加载都走 PCIe，但是是 **按页 (4KB)** 进行
3. Page Fault 处理有 ~15 µs 固定开销
4. 3,145,728 页 × 15 µs = 47 秒 (无法并行化)

### 5.3 为什么 cuMemPrefetchAsync 也救不了

`cuMemPrefetchAsync` 的工作原理：
1. 提交预取请求到 Copy Engine
2. Copy Engine 执行批量 DMA（如果有东西可以迁移）
3. **前提条件**：目标位置有空间

**在超卖场景下**：
- 目标位置（GPU）已满
- 要迁移数据进来，必须先驱逐现有数据
- 驱动的策略是**不主动驱逐**，而是等待 Page Fault
- 因此预取请求被静默忽略

---

## 6. 结论

### 6.1 根因总结

| 层次 | 问题 |
|------|------|
| 最表层 | 多任务性能只有单任务的 3% |
| 中间层 | 任务切换时数据恢复需要 ~50 秒 |
| 根本原因 | UVM 按需分页 + 显存超卖 = 不可避免的 Page Fault 风暴 |
| 技术限制 | cuMemAdvise/cuMemPrefetchAsync 在显存满时被驱动忽略 |

### 6.2 方案建议

**短期（推荐）**：
- 实现串行执行模式
- 预期效果：多任务总完成时间从 5000+ 秒降至 ~640 秒 (4 任务 × 160 秒)

**中期**：
- 完善显存感知调度，智能决定并发数

**长期（如需要低延迟切换）**：
- 实现 Manual Swap，将切换时间从 50 秒降至 2-3 秒

### 6.3 关键认知更新

之前的分析报告提出的 `cuMemPrefetchAsync` 方案虽然理论正确，但**忽略了显存满载时驱动会忽略预取请求这一关键行为**。

真正的解决方案必须绕过 UVM 的自动管理，或者从调度层面避免超卖。
